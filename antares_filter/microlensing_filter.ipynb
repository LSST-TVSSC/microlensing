{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a1fb617-42cf-4611-9810-f765318e4825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T15:56:07.110801Z",
     "iopub.status.busy": "2026-02-05T15:56:07.110321Z",
     "iopub.status.idle": "2026-02-05T15:56:07.113640Z",
     "shell.execute_reply": "2026-02-05T15:56:07.113061Z",
     "shell.execute_reply.started": "2026-02-05T15:56:07.110779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import antares\n",
    "#from antares_devkit.models import DevKitLocus\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "503c3fc5-0cd0-4f57-b731-f3a9cde621e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T15:58:30.615234Z",
     "iopub.status.busy": "2026-02-05T15:58:30.614770Z",
     "iopub.status.idle": "2026-02-05T15:58:35.703087Z",
     "shell.execute_reply": "2026-02-05T15:58:35.701999Z",
     "shell.execute_reply.started": "2026-02-05T15:58:30.615208Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jaeger tracer already initialized, skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prometheus failed to start with [Errno 98] Address already in use\n",
      "Testing loading a random Locus with `dk.get_locus()`...\n",
      "\n",
      "ANTARES v2.11.0 DevKit is ready!\n",
      "Website: https://antares.noirlab.edu\n",
      "Documentation: https://nsf-noirlab.gitlab.io/csdc/antares/antares/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import antares.devkit as dk\n",
    "dk.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba51bef7-33a3-4365-a3be-ff930bdc96c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T15:55:05.172386Z",
     "iopub.status.busy": "2026-02-05T15:55:05.171858Z",
     "iopub.status.idle": "2026-02-05T15:55:05.181571Z",
     "shell.execute_reply": "2026-02-05T15:55:05.181038Z",
     "shell.execute_reply.started": "2026-02-05T15:55:05.172367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a Paczyński microlensing model\n",
    "def paczynski(t, t0, u0, tE, F_s):\n",
    "    \"\"\"\n",
    "    Paczyński microlensing light curve model\n",
    "    t0 : peak time\n",
    "    u0 : impact parameter\n",
    "    tE : Einstein crossing time\n",
    "    F_s : source flux\n",
    "    F_b : blended flux\n",
    "    \"\"\"\n",
    "    u = np.sqrt(u0**2 + ((t - t0) / tE) ** 2)\n",
    "    A = (u**2 + 2) / (u * np.sqrt(u**2 + 4))\n",
    "    return F_s * (A) + (1-F_s)\n",
    "    \n",
    "def fit_paczynski(times, mags, flxs, flx_errs):\n",
    "    \"\"\"\n",
    "    Fit the Paczyński microlensing model to flux data.\n",
    "    Returns best-fit parameters and chi-squared value.\n",
    "    \"\"\"\n",
    "    if len(times) < 4:\n",
    "        return None, None  # Not enough data\n",
    "\n",
    "    # initial guesses\n",
    "    t0_guess = times[np.argmin(flxs)]\n",
    "    u0_guess = 1.0 / (np.max(flxs))\n",
    "\n",
    "    tE_guess = 20.0\n",
    "    F0_guess = 0.5\n",
    "\n",
    "\n",
    "    initial_guess = [t0_guess, u0_guess, tE_guess, F0_guess]\n",
    "\n",
    "    bounds = (\n",
    "                        [times.min() - 50, 0, 1.0, 0.0],\n",
    "                        [times.max() + 50, np.inf, 500.0, 1]\n",
    "                    )\n",
    "\n",
    "\n",
    "    try:\n",
    "        popt, _ = curve_fit(\n",
    "            paczynski,\n",
    "            times, flxs,\n",
    "            p0=initial_guess,\n",
    "            sigma=flx_errs,\n",
    "            bounds=bounds,\n",
    "\n",
    "            maxfev=5000\n",
    "        )\n",
    "        chi2 = np.sum(((flxs - paczynski(times, *popt)) / flx_errs) ** 2) / len(times)\n",
    "        return popt, chi2\n",
    "    except Exception as e:\n",
    "        print(f\"  Paczynski fitting error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def mag_to_flux(mag, F0=1.0):\n",
    "    \"\"\"\n",
    "    Convert magnitude to flux.\n",
    "    \n",
    "    Parameters:\n",
    "    - mag : magnitude (float or array)\n",
    "    - F0 : reference flux (zeropoint), default=1.0 for relative flux\n",
    "    \n",
    "    Returns:\n",
    "    - flux : flux corresponding to the magnitude\n",
    "    \"\"\"\n",
    "    flux = F0 * 10**(-0.4 * mag)\n",
    "    flux = flux/np.min(flux)\n",
    "    return flux\n",
    "    \n",
    "def magerr_to_fluxerr(mag, mag_err, F0=1.0):\n",
    "    \"\"\"\n",
    "    Convert magnitude uncertainty to flux uncertainty.\n",
    "    \n",
    "    Parameters:\n",
    "    - mag : magnitude value or array\n",
    "    - mag_err : magnitude uncertainty value or array\n",
    "    - F0 : zeropoint flux (default=1.0 for relative flux)\n",
    "    \n",
    "    Returns:\n",
    "    - flux_err : flux uncertainty\n",
    "    \"\"\"\n",
    "    flux = mag_to_flux(mag, F0)\n",
    "    flux_err = 0.4 * np.log(10) * flux * mag_err\n",
    "    return flux_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d639a6d1-4165-4dd8-8a5a-71aef88531e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:55:34.821224Z",
     "iopub.status.busy": "2026-02-03T17:55:34.820800Z",
     "iopub.status.idle": "2026-02-03T17:55:34.828725Z",
     "shell.execute_reply": "2026-02-03T17:55:34.828200Z",
     "shell.execute_reply.started": "2026-02-03T17:55:34.821207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chi squared functions for BAGLE model\n",
    "def calc_chi2_mean(data, n_phot_sets = 1, verbose=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : str or dict, optional\n",
    "            model_params = 'best' will load up the best solution and calculate\n",
    "            the chi^2 based on those values. Alternatively, pass in a dictionary\n",
    "            with the model parameters to use.\n",
    "        \"\"\"\n",
    "        # Get likelihoods.\n",
    "        lnL_phot = log_likely_photometry(data)\n",
    "\n",
    "        # Lists to store lnL, chi2, and constants for each filter.\n",
    "        chi2_phot_filts = []\n",
    "        lnL_const_phot_filts = []\n",
    "    \n",
    "        for nn in range(n_phot_sets):\n",
    "            mag_err = data['mag_err' + str(nn + 1)]\n",
    "            \n",
    "            # Calculate the lnL for just a single filter.\n",
    "            lnL_phot_nn = log_likely_photometry(data, nn)\n",
    "\n",
    "            # Calculate the chi2 and constants for just a single filter.\n",
    "            lnL_const_phot_nn = -0.5 * np.log(2.0 * math.pi * mag_err**2)\n",
    "            lnL_const_phot_nn = lnL_const_phot_nn.sum()\n",
    "            \n",
    "            chi2_phot_nn = (lnL_phot_nn - lnL_const_phot_nn) / -0.5\n",
    "\n",
    "            # Save to our lists\n",
    "            chi2_phot_filts.append(chi2_phot_nn)\n",
    "            lnL_const_phot_filts.append(lnL_const_phot_nn)\n",
    "\n",
    "        lnL_const_phot = sum(lnL_const_phot_filts)\n",
    "\n",
    "\n",
    "        # Calculate chi2.\n",
    "        chi2 = (lnL_phot - lnL_const_phot) / -0.5\n",
    "\n",
    "        if verbose:\n",
    "            fmt = '{0:13s} = {1:f} '\n",
    "            for ff in range(n_phot_sets):\n",
    "                print(fmt.format('chi2_phot' + str(ff + 1), chi2_phot_filts[ff]))\n",
    "                \n",
    "            print(fmt.format('chi2', chi2))\n",
    "\n",
    "        return chi2\n",
    "\n",
    "def log_likely_photometry(data, n_phot_sets = 1, verbose = False):\n",
    "\n",
    "    lnL_phot = 0.0\n",
    "\n",
    "    for i in range(n_phot_sets):\n",
    "        t_phot = data['t_phot' + str(i + 1)]\n",
    "        mag = data['mag' + str(i + 1)]\n",
    "        mag_err = data['mag_err' + str(i + 1)]\n",
    "\n",
    "        # commenting out weight stuff for now\n",
    "        #weight = self.weights[i]\n",
    "        lnL_phot_unwgt = log_likely_photometry_each(t_phot, mag, mag_err, i)\n",
    "        lnL_phot_i = lnL_phot_unwgt #* weight\n",
    "        lnL_phot += lnL_phot_i\n",
    "\n",
    "        if verbose:\n",
    "            print(f'lnL_phot: i = {i} L_unwgt = {lnL_phot_unwgt:15.1f}, L_wgt = {lnL_phot_i:15.1f}, weight = {weight:.1e}')\n",
    "\n",
    "\n",
    "    return lnL_phot\n",
    "\n",
    "def log_likely_photometry_each(t_obs, mag_obs, mag_err_obs, filt_idx=0):\n",
    "    \"\"\"\n",
    "    Get the natural log of the likelihood for the input photometric data in the \n",
    "    specified filter or data sets. Note, this function returns a list and it \n",
    "    is the full ln(likelihood), including the normalization constant. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t_obs : array_like\n",
    "        List of times in MJD for the observations. \n",
    "    mag_obs : array_like\n",
    "        List of observed photometric measurements of the microlensing event in magnitudes. \n",
    "        Length must be the same as t_obs.\n",
    "    mag_obs_err : array_like\n",
    "        List of observed photometric uncertainties of the microlensing event in magnitudes. \n",
    "        Length must be the same as t_obs.\n",
    "    filt_idx : int, optional\n",
    "        Index of the photometric filter or data set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ln_L : array_like\n",
    "        List of ln(likelihood) for each photometric measurement. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    chi2_m = get_chi2_photometry_mean(t_obs, mag_obs, mag_err_obs, filt_idx=filt_idx)\n",
    "\n",
    "    lnL_const_m = get_lnL_constant(mag_err_obs)\n",
    "\n",
    "    lnL = (-0.5 * chi2_m) + lnL_const_m\n",
    "\n",
    "    return lnL.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0afe7a-1ca7-4e31-9255-fa8c9255d9ce",
   "metadata": {},
   "source": [
    "# Writing a preliminary microlensing filter that reads in the photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd23f27-e51b-4560-a5dd-bc6cb959e56e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T15:55:11.968690Z",
     "iopub.status.busy": "2026-02-05T15:55:11.968235Z",
     "iopub.status.idle": "2026-02-05T15:55:12.640562Z",
     "shell.execute_reply": "2026-02-05T15:55:12.639963Z",
     "shell.execute_reply.started": "2026-02-05T15:55:11.968669Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "import numpy as np\n",
    "from astropy.table import MaskedColumn\n",
    "import warnings\n",
    "import astropy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import skew\n",
    "#from antares.devkit.models import BaseFilter\n",
    "from antares_client import search\n",
    "#from bagle import model, model_fitter\n",
    "from astropy.stats import sigma_clip\n",
    "from scipy.stats import chi2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6265a270-ba5e-447e-ae71-e9b07e9ca381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T16:03:10.286541Z",
     "iopub.status.busy": "2026-02-05T16:03:10.285983Z",
     "iopub.status.idle": "2026-02-05T16:03:10.371674Z",
     "shell.execute_reply": "2026-02-05T16:03:10.371029Z",
     "shell.execute_reply.started": "2026-02-05T16:03:10.286518Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'antares.devkit' has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from antares_microlensing_filter import microlensing\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mmicrolensing\u001b[39;00m(\u001b[43mantares\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevkit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mBaseFilter):    \n\u001b[1;32m      4\u001b[0m     INPUT_LOCUS_PROPERTIES \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mztf_object_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     ]\n\u001b[1;32m      8\u001b[0m     REQUIRED_TAGS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlc_feature_extractor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'antares.devkit' has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "#from antares_microlensing_filter import microlensing\n",
    "\n",
    "class microlensing(antares.devkit.model.BaseFilter):    \n",
    "    INPUT_LOCUS_PROPERTIES = [\n",
    "        'ztf_object_id',\n",
    "    ]\n",
    "\n",
    "    REQUIRED_TAGS = ['lc_feature_extractor']\n",
    "\n",
    "    OUTPUT_TAGS = [\n",
    "        {\n",
    "            'name': 'microlensing_candidate',\n",
    "            'description': 'Locus - a transient candidate - exhibits a microlensing-like variability',\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    def make_lc(self, locus):\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            # The cast of locus.timeseries: astropy.table.Table to a pandas\n",
    "            # dataframe results in the conversion of some integer-valued\n",
    "            # columns to floating point represntation. This can result in a\n",
    "            # number of noisy warning so we will catch & ignore them for the\n",
    "            # next couple of lines.\n",
    "            warnings.simplefilter(\"ignore\", astropy.table.TableReplaceWarning)\n",
    "            df = locus.timeseries().to_pandas()\n",
    "\n",
    "        data = df[['ant_mjd', 'ztf_fid', 'ztf_magpsf', 'ztf_sigmapsf']]\n",
    "        \n",
    "        dn = data.dropna()\n",
    "        times=dn['ant_mjd'][dn['ztf_fid']==1]\n",
    "        mags = dn['ztf_magpsf'][dn['ztf_fid']==1]\n",
    "        mags_err = dn['ztf_sigmapsf'][dn['ztf_fid']==1]\n",
    "        flxs = mag_to_flux(mags)\n",
    "        flx_errs = magerr_to_fluxerr(mags, mags_err)\n",
    "        \n",
    "\n",
    "    def is_known_other_phenomenon(self, locus, locus_params):\n",
    "        \"\"\"\n",
    "        Method to check the locus' pre-existing parameters indicated that it has\n",
    "        been identified or is likely to be a variable of a type other than microlensing\n",
    "\n",
    "        :param locus:\n",
    "        :param locus_params:\n",
    "        :return: boolean\n",
    "        \"\"\"\n",
    "\n",
    "        # Default result is not a known variable\n",
    "        known_var = False\n",
    "        \n",
    "        # Tunable detection thresholds.\n",
    "        # Ref: Sokolovsky et al. 2016: https://ui.adsabs.harvard.edu/abs/2017MNRAS.464..274S/abstract\n",
    "        period_peak_sn_threshold = 20.0  # Based on tests with ZTF alerts\n",
    "        stetson_k_threshold = 0.8  # The expected K-value for a constant lightcurve with Gaussian noise\n",
    "\n",
    "        # Check for periodicity\n",
    "        if locus_params['feature_period_s_to_n_0_magn_r'] >= period_peak_sn_threshold:\n",
    "            known_var = True\n",
    "\n",
    "        # Check Stetson-K index\n",
    "        if locus_params['feature_stetson_k_magn_r'] <= stetson_k_threshold:\n",
    "            known_var = True\n",
    "\n",
    "        # Check whether this event is associated with a GW event\n",
    "        # TODO port to new value\n",
    "        #if 'plausible_gw_events_assoc' in locus.alert.properties.keys():\n",
    "        #    known_var = True\n",
    "\n",
    "        # If the alert has parameters from JPL Horizons, then it is likely cause by\n",
    "        # a Solar System object\n",
    "        if 'horizons_targetname' in locus_params.keys():\n",
    "            known_var = True\n",
    "\n",
    "        # Check whether the ANTARES crossmatch against known galaxy catalogs threw up any matches\n",
    "        # The locus.catalog_objects attribute is a dictionary of lists of known objects for each \n",
    "        # catalogs.  If a match has been found, then the key for the corresponding catalog will be \n",
    "        # in the list of keys.  So we can use that to check for matches with galaxy catalogs. \n",
    "        # Of those available in the list the Gemini NIR survey of known quasars is the closest\n",
    "        if 'gnirs_dqs' in locus.catalog_objects.keys():\n",
    "            known_var = True\n",
    "            \n",
    "        return known_var\n",
    "\n",
    "    def calculate_eta(self, mag):\n",
    "        \"\"\" Via puzle https://github.com/jluastro/puzle/blob/main/puzle/stats.py\"\"\"\n",
    "        delta = np.sum((np.diff(mag)*np.diff(mag)) / (len(mag)-1))\n",
    "        variance = np.var(mag)\n",
    "        eta = delta / variance\n",
    "        return eta\n",
    "\n",
    "    def return_eta_residual_slope_offset(self):\n",
    "        \"\"\" \n",
    "        Via puzle https://github.com/jluastro/puzle/blob/main/puzle/cands.py\n",
    "        TODO is 6 months and a year - calculate slope and intercept based on real Rubin data\n",
    "        \"\"\"\n",
    "        slope = 3.8187919463087248\n",
    "        offset = -0.07718120805369133\n",
    "        return slope, offset\n",
    "\n",
    "    def make_bagle_data_dir(self, times, mags, errors):\n",
    "        data = {}\n",
    "        data['target'] = 'single_event'\n",
    "        data['phot_data'] = 'alert'\n",
    "        data['phot_files'] = ['locus']\n",
    "        data['ast_data'] = 'None'\n",
    "        data['ast_files'] = []\n",
    "        \n",
    "        data['t_phot1'] = times\n",
    "        data['mag1'] = mags\n",
    "        data['mag_err1'] = errors\n",
    "\n",
    "        return data\n",
    "\n",
    "    def is_microlensing_candidate(self, locus, times, mags, errors, verbose):\n",
    "        \"\"\"\n",
    "        Example of a set of Microlensing detection criteria\n",
    "        \"\"\"\n",
    "        if len(times) < 10:  # Too few data points\n",
    "            if verbose == True:\n",
    "                print('Too Few Datapoints')\n",
    "            return False\n",
    "\n",
    "        # Extract the full parameter set from the locus and the alert\n",
    "        locus_params = locus.properties\n",
    "\n",
    "        # Use the pre-calculated properties of the locus to eliminate those\n",
    "        # which show signs of variability, e.g. in their periodicity signature or\n",
    "        # the Stetson-K index\n",
    "        known_var = self.is_known_other_phenomenon(locus, locus_params)\n",
    "        if known_var:\n",
    "            if verbose == True:\n",
    "                print('Other known phenomenon')\n",
    "            return False\n",
    "\n",
    "        # Sort data by time\n",
    "        sorted_idx = np.argsort(times)\n",
    "        times, mags, errors = times[sorted_idx], mags[sorted_idx], errors[sorted_idx]\n",
    "        npts = len(times)\n",
    "\n",
    "        # 1. Check for smoothness (low skewness means symmetric light curve)\n",
    "        # TODO: Check for threshold with parallax and maybe remove or lower threshold\n",
    "        if abs(skew(mags)) > 1:\n",
    "            if verbose == True:\n",
    "                print('Too skewed')\n",
    "            return False\n",
    "\n",
    "        # TODO is 6 months and a year - calculate this based on percentile of real data\n",
    "        eta_thresh = 1.255 # Avg from ZTF level 2 (low eta)\n",
    "        # Do check for existance since if there's only one band of data, only one will exist\n",
    "        eta_r_exists = 'feature_eta_e_magn_r' in locus_params.keys()\n",
    "        eta_g_exists = 'feature_eta_e_magn_g' in locus_params.keys()\n",
    "        eta_r = locus_params['feature_eta_e_magn_r']\n",
    "        eta_g = locus_params['feature_eta_e_magn_g']\n",
    "        if eta_r_exists and eta_g_exists:\n",
    "            if eta_r >= eta_thresh and eta_g >= eta_thresh:\n",
    "                if verbose == True:\n",
    "                    print('Failed von Neumann threshold')\n",
    "                return False\n",
    "        elif eta_r_exists:\n",
    "            if eta_r >= eta_thresh:\n",
    "                if verbose == True:\n",
    "                    print('Failed von Neumann threshold')\n",
    "                return False\n",
    "        elif eta_g_exists:\n",
    "            if eta_g >= eta_thresh:\n",
    "                if verbose == True:\n",
    "                    print('Failed von Neumann threshold')\n",
    "                return False\n",
    "\n",
    "        # 2. Check variability (microlensing should have a clear peak)\n",
    "        # Decrease threshold with longer baseline\n",
    "        # Q for broker - 365 days or full lightcurve?\n",
    "        if np.ptp(mags) < 0.5:  # Peak-to-peak magnitude difference\n",
    "            if verbose == True:\n",
    "                print('Too small magnitude change')\n",
    "            return False\n",
    "\n",
    "        flxs = mag_to_flux(mags)\n",
    "        flx_errs = magerr_to_fluxerr(mags, errors)\n",
    "\n",
    "        # 3. Perform a lightweight template fit (Paczyński model)\n",
    "\n",
    "        popt, chi2_paczynski = fit_paczynski(times, mags, flxs, flx_errs)\n",
    "        resid = flxs - paczynski(times, *popt)\n",
    "        chi2_val = np.sum((resid / flx_errs) ** 2) / npts\n",
    "\n",
    "        # 4. Apply a simple chi2 threshold\n",
    "        if chi2_val > 2:  # Poor-fit light curves fails\n",
    "            if verbose == True:\n",
    "                print('Failed simple fit chi^2 threshold')\n",
    "            return False\n",
    "        # except RuntimeError:\n",
    "        #     return False  # Fit failed\n",
    "\n",
    "        # 5. Check that the residual isn't correlated in all avaliable bands\n",
    "        eta_resid = self.calculate_eta(resid)\n",
    "        eta_slope, eta_offset = self.return_eta_residual_slope_offset()\n",
    "        if eta_r_exists and eta_g_exists:\n",
    "            if (eta_resid < eta_r*eta_slope + eta_offset) and (eta_resid < eta_g*eta_slope + eta_offset):\n",
    "                if verbose == True:\n",
    "                    print('Failed eta residual threshold')\n",
    "                return False\n",
    "        elif eta_r_exists:\n",
    "            if (eta_resid < eta_r*eta_slope + eta_offset):\n",
    "                if verbose == True:\n",
    "                    print('Failed eta residual threshold')\n",
    "                return False\n",
    "        elif eta_g_exists:\n",
    "            if (eta_resid < eta_g*eta_slope + eta_offset):\n",
    "                if verbose == True:\n",
    "                    print('Failed eta residual threshold')\n",
    "                return False\n",
    "\n",
    "        # TODO - Rache potentially query full lightcurve if not already there and if possible\n",
    "\n",
    "        # outbase = 'microlens_fit_'\n",
    "        # data = self.make_bagle_data_dir(times, mags, errors)\n",
    "        # fitter = model_fitter.PSPL_Solver(data,\n",
    "        #                      model.PSPL_Phot_noPar_Param2,\n",
    "        #                      importance_nested_sampling = False,\n",
    "        #                      n_live_points=200,\n",
    "        #                      outputfiles_basename= outbase)\n",
    "        \n",
    "        \n",
    "        # fitter.priors['tE'] = model_fitter.make_gen(1, 400)\n",
    "        # fitter.priors['t0'] = model_fitter.make_gen(60960, 61000) #FIXME replace for Rubin\n",
    "        # fitter.priors['b_sff1'] = model_fitter.make_gen(0.001, 1.25)\n",
    "\n",
    "        # fitter.solve()\n",
    "\n",
    "        # fit_vals = fitter.get_best_fit(def_best='map')\n",
    "        # chi2_red_bagle = fitter.calc_chi2(params=fit_vals)/(npts - len(fit_vals))\n",
    "\n",
    "        # if chi2_red_bagle > 3:\n",
    "        #     if verbose == True:\n",
    "        #         print('Failed BAGLE fit chi^2 threshold')\n",
    "        #     return False\n",
    "\n",
    "        # fit_vals['b_sff'] = fit_vals.pop('b_sff1')\n",
    "        # fit_vals['mag_base'] = fit_vals.pop('mag_base1')\n",
    "        # for key in fit_vals.keys():\n",
    "        #     locus.set_property('feature_microlensing_' + key, fit_vals[key])\n",
    "        # locus.set_property('feature_microlensing_chi2_red', chi2_red_bagle)\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def _run(self, locus):\n",
    "        print('Processing Locus:', locus.locus_id)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", astropy.table.TableReplaceWarning)\n",
    "            df = locus.timeseries().to_pandas()\n",
    "\n",
    "        data = df[['ant_mjd', 'ztf_fid', 'ztf_magpsf', 'ztf_sigmapsf']].dropna()\n",
    "        \n",
    "        \n",
    "        # Split into g-band and i-band\n",
    "        for band in [1, 2]:  # 1 = g-band, 2 = i-band\n",
    "            band_data = data[data['ztf_fid'] == band]\n",
    "            times, mags, errors = band_data['ant_mjd'].values, band_data['ztf_magpsf'].values, band_data['ztf_sigmapsf'].values\n",
    "            \n",
    "            if self.is_microlensing_candidate(locus, times, mags, errors, verbose = True):\n",
    "                print(f'Locus {locus.locus_id} is a microlensing candidate in band {band}')\n",
    "                locus.tags.add('microlensing_candidate')\n",
    "        \n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad36902a-7c4c-4e5e-87ef-408ae02f9898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:05:35.547361Z",
     "iopub.status.busy": "2026-02-03T17:05:35.546992Z",
     "iopub.status.idle": "2026-02-03T17:05:35.558178Z",
     "shell.execute_reply": "2026-02-03T17:05:35.557252Z",
     "shell.execute_reply.started": "2026-02-03T17:05:35.547332Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_lightcurve(locus, include_microlensing = True):\n",
    "    df = locus.timeseries().to_pandas()\n",
    "    \n",
    "    data = df[['ant_mjd', 'ztf_fid', 'ztf_magpsf', 'ztf_sigmapsf']]\n",
    "    \n",
    "    dn = data.dropna()\n",
    "    times=dn['ant_mjd'][dn['ztf_fid']==1]\n",
    "    mags = dn['ztf_magpsf'][dn['ztf_fid']==1]\n",
    "    mags_err = dn['ztf_sigmapsf'][dn['ztf_fid']==1]\n",
    "\n",
    "    if include_microlensing and 'microlensing_candidate' in locus.tags:\n",
    "        properties = locus.properties.keys()\n",
    "        microlensing_params = {}\n",
    "        for property in properties:\n",
    "            if property == 'feature_microlensing_chi2_red':\n",
    "                continue\n",
    "            if 'feature_microlensing' in property:\n",
    "               microlensing_params[property[21:]] = locus.properties[property] \n",
    "        pspl_mod = model.PSPL_Phot_noPar_Param2(**microlensing_params)\n",
    "        mod_times = np.arange(times[0], times[-1], 1)\n",
    "        mod_mags = pspl_mod.get_photometry(mod_times)\n",
    "        plt.plot(mod_times, mod_mags)\n",
    "\n",
    "    plt.errorbar(times, mags, yerr=mags_err, marker = '.', linestyle = 'None')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9284b379-f912-4edf-adc9-59ff11630fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:55:45.222471Z",
     "iopub.status.busy": "2026-02-03T17:55:45.221967Z",
     "iopub.status.idle": "2026-02-03T17:55:45.769493Z",
     "shell.execute_reply": "2026-02-03T17:55:45.768661Z",
     "shell.execute_reply.started": "2026-02-03T17:55:45.222453Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'antares.devkit.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mantares\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DevKitLocus\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'antares.devkit.models'"
     ]
    }
   ],
   "source": [
    "#from antares.devkit.models import DevKitLocus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d238f85-804b-415a-9fd8-809dd75e33ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T15:55:25.055234Z",
     "iopub.status.busy": "2026-02-05T15:55:25.054641Z",
     "iopub.status.idle": "2026-02-05T15:55:25.058894Z",
     "shell.execute_reply": "2026-02-05T15:55:25.058067Z",
     "shell.execute_reply.started": "2026-02-05T15:55:25.055208Z"
    }
   },
   "outputs": [],
   "source": [
    "import antares.devkit as dk\n",
    "from antares.devkit import Locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512487e0-c99a-47aa-bc44-7fb70c189177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:04:25.913211Z",
     "iopub.status.busy": "2026-02-03T18:04:25.912946Z",
     "iopub.status.idle": "2026-02-03T18:04:26.282071Z",
     "shell.execute_reply": "2026-02-03T18:04:26.281252Z",
     "shell.execute_reply.started": "2026-02-03T18:04:25.913195Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'locus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#locus = search.get_by_id(\"ANT20254r1cmsq703sa\") # Alerted microlensing from AlerCE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#locus = search.get_by_id(\"ANT2025ew17s5s6371e\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#locus = search.get_by_id(\"ANT2025990smuyidkid\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#dk_locus = Locus.parse_obj(locus.to_devkit())\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m dk_locus \u001b[38;5;241m=\u001b[39m \u001b[43mlocus\u001b[49m\u001b[38;5;241m.\u001b[39mto_devkit()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'locus' is not defined"
     ]
    }
   ],
   "source": [
    "#locus = search.get_by_id(\"ANT20254r1cmsq703sa\") # Alerted microlensing from AlerCE\n",
    "#locus = search.get_by_id(\"ANT2025ew17s5s6371e\")\n",
    "#locus = search.get_by_id(\"ANT2025990smuyidkid\")\n",
    "#locus = search.get_by_id(\"ANT2023wuk92lk9fz76\")\n",
    "dk_locus = Locus.model_validate(locus.to_devkit()) \n",
    "#report = dk.run_filter(microlensing, locus = \"ANT20254r1cmsq703sa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b2075dce-0447-45a7-9199-437d6f36e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high_flux_ratio_wrt_nn', 'lc_feature_extractor'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dk_locus.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af6e772-870d-4a68-baba-f99331425474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T15:55:37.968768Z",
     "iopub.status.busy": "2026-02-05T15:55:37.968232Z",
     "iopub.status.idle": "2026-02-05T15:55:38.223203Z",
     "shell.execute_reply": "2026-02-05T15:55:38.222094Z",
     "shell.execute_reply.started": "2026-02-05T15:55:37.968745Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class microlensing with abstract method run",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m microlens_filter \u001b[38;5;241m=\u001b[39m \u001b[43mmicrolensing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class microlensing with abstract method run"
     ]
    }
   ],
   "source": [
    "microlens_filter = microlensing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421a5dff-dbfd-45f8-ba31-7632e077981b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T15:59:27.852253Z",
     "iopub.status.busy": "2026-02-05T15:59:27.851646Z",
     "iopub.status.idle": "2026-02-05T15:59:27.931055Z",
     "shell.execute_reply": "2026-02-05T15:59:27.930190Z",
     "shell.execute_reply.started": "2026-02-05T15:59:27.852230Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class microlensing with abstract method run",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m report\u001b[38;5;241m=\u001b[39m \u001b[43mdk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmicrolensing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mANT2023wuk92lk9fz76\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data0/sw/antares-kernel/lib/python3.9/site-packages/antares/devkit/filter/__init__.py:53\u001b[0m, in \u001b[0;36mrun_filter\u001b[0;34m(f, locus, verbose)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mTest a Filter.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m:param verbose: if True, print detailed log\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m log_init(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, system_wide\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 53\u001b[0m filter_executable \u001b[38;5;241m=\u001b[39m \u001b[43mget_filter_executable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _run_filter(filter_executable, locus\u001b[38;5;241m=\u001b[39mlocus)\n",
      "File \u001b[0;32m/data0/sw/antares-kernel/lib/python3.9/site-packages/antares/devkit/filter/__init__.py:29\u001b[0m, in \u001b[0;36mget_filter_executable\u001b[0;34m(filter_code)\u001b[0m\n\u001b[1;32m     27\u001b[0m filter_instance: Filter\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(filter_code) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(filter_code, Filter):\n\u001b[0;32m---> 29\u001b[0m     filter_instance \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filter_code, Filter):\n\u001b[1;32m     31\u001b[0m     filter_instance \u001b[38;5;241m=\u001b[39m filter_code\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class microlensing with abstract method run"
     ]
    }
   ],
   "source": [
    "report= dk.run_filter(microlensing, locus=\"ANT2023wuk92lk9fz76\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959bd7a3-13da-499f-8012-fb68e7f75614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T15:56:23.847259Z",
     "iopub.status.busy": "2026-02-05T15:56:23.846250Z",
     "iopub.status.idle": "2026-02-05T15:56:23.871500Z",
     "shell.execute_reply": "2026-02-05T15:56:23.870747Z",
     "shell.execute_reply.started": "2026-02-05T15:56:23.847214Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dk_locus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Execute the microlensing filter on the locus\u001b[39;00m\n\u001b[1;32m      2\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m report \u001b[38;5;241m=\u001b[39m microlensing\u001b[38;5;241m.\u001b[39mrun(locus\u001b[38;5;241m=\u001b[39m\u001b[43mdk_locus\u001b[49m)\u001b[38;5;66;03m#\"ANT2023wuk92lk9fz76\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39mt0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dk_locus' is not defined"
     ]
    }
   ],
   "source": [
    "# Execute the microlensing filter on the locus\n",
    "t0 = time.time()\n",
    "report = microlensing.run(locus=dk_locus)#\"ANT2023wuk92lk9fz76\")\n",
    "print(time.time() -t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "27d15268-3575-4dd4-aea5-b8520c5ca56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FilterReturn(status='Succeeded', exception_name=None, exception_message=None, traceback=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cb84cca-7098-4f20-ac48-e4b618216232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T16:18:10.665898Z",
     "iopub.status.busy": "2026-02-05T16:18:10.665567Z",
     "iopub.status.idle": "2026-02-05T16:18:10.690643Z",
     "shell.execute_reply": "2026-02-05T16:18:10.689765Z",
     "shell.execute_reply.started": "2026-02-05T16:18:10.665874Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_lightcurve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_lightcurve\u001b[49m(dk_locus)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_lightcurve' is not defined"
     ]
    }
   ],
   "source": [
    "plot_lightcurve(dk_locus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01a6a320-3b9e-4fe8-82ed-b0789fa80915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T16:18:22.438764Z",
     "iopub.status.busy": "2026-02-05T16:18:22.438097Z",
     "iopub.status.idle": "2026-02-05T16:18:22.462207Z",
     "shell.execute_reply": "2026-02-05T16:18:22.461514Z",
     "shell.execute_reply.started": "2026-02-05T16:18:22.438729Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'antares.devkit.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mantares\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filter_report\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'antares.devkit.utils'"
     ]
    }
   ],
   "source": [
    "from antares.devkit.utils import filter_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5af7d922-4fd6-43c8-a75c-fade49204ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T16:18:31.000222Z",
     "iopub.status.busy": "2026-02-05T16:18:30.999693Z",
     "iopub.status.idle": "2026-02-05T16:18:31.030844Z",
     "shell.execute_reply": "2026-02-05T16:18:31.029761Z",
     "shell.execute_reply.started": "2026-02-05T16:18:31.000200Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'antares_client.search' has no attribute 'get_random_locus_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m random_ids \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_locus_ids\u001b[49m(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      2\u001b[0m ts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, random_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(random_ids):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'antares_client.search' has no attribute 'get_random_locus_ids'"
     ]
    }
   ],
   "source": [
    "random_ids = search.get_random_locus_ids(n=50)\n",
    "ts = np.zeros(50)\n",
    "for i, random_id in enumerate(random_ids):\n",
    "    locus = search.get_by_id(random_id)\n",
    "    dk_locus = DevKitLocus.model_validate(locus.to_devkit())\n",
    "    t0 = time.time()\n",
    "    report = microlens_filter.run(locus=dk_locus)\n",
    "    t_tot = time.time() - t0\n",
    "    print(t_tot)\n",
    "    ts[i] = t_tot\n",
    "    plot_lightcurve(dk_locus)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d801b7f8-d9fa-4c28-b19f-8e6783fc99a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04685897350311279"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0255e7-e006-458f-9ea0-e4192f126f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ANTARES,Py3.9.18)",
   "language": "python",
   "name": "antares_py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
