{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4703d404-1059-44c8-924b-b52547839bbe",
   "metadata": {},
   "source": [
    "# Search for Microlensing events in DP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881445ed-db94-4b0b-bdea-b19ebd038e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.lines as mlines\n",
    "import itertools\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from lsst.rsp import get_tap_service\n",
    "from lsst.daf.butler import Butler\n",
    "import lsst.afw.display as afw_display\n",
    "import lsst.sphgeom as sphgeom\n",
    "import lsst.geom as geom\n",
    "from lsst.utils.plotting import (get_multiband_plot_colors,\n",
    "                                 get_multiband_plot_symbols,\n",
    "                                 get_multiband_plot_linestyles)\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "import weightedstats as ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac46feb-3f21-47f3-a995-b0a6e6066bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = get_tap_service(\"tap\")\n",
    "assert service is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74de9a-5bbb-4f5a-8bbe-20c1d5c1f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "butler = Butler('dp1', collections=\"LSSTComCam/DP1\")\n",
    "assert butler is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a624a1b-5dd6-48ba-923e-9cf0a1acdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_cen = 95.0\n",
    "dec_cen = -25.0\n",
    "radius = 1.0\n",
    "region = sphgeom.Region.from_ivoa_pos(f\"CIRCLE {ra_cen} {dec_cen} {radius}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043a9cd-9a70-47f6-9987-8274fa4939c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT objectId, coord_ra, coord_dec,\n",
    "               u_psfMag, u_cModelMag, g_psfMag, g_cModelMag,\n",
    "               r_psfMag, r_cModelMag, i_psfMag, i_cModelMag,\n",
    "               z_psfMag, z_cModelMag, y_psfMag, y_cModelMag,\n",
    "               refExtendedness\n",
    "        FROM dp1.Object\n",
    "        WHERE CONTAINS(POINT('ICRS', coord_ra, coord_dec),\n",
    "              CIRCLE('ICRS', {}, {}, {})) = 1\n",
    "        ORDER BY objectId\n",
    "        \"\"\".format(ra_cen, dec_cen, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da77ed-67ea-49c1-82b4-820ec4414e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = service.submit_job(query)\n",
    "job.run()\n",
    "job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "print('Job phase is', job.phase)\n",
    "if job.phase == 'ERROR':\n",
    "    job.raise_if_error()\n",
    "assert job.phase == 'COMPLETED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba8422-b1f4-4a5a-b9d0-4e544a27e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "objtab = job.fetch_result().to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03317e-e14e-49c3-b824-f86bb2606868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select objects with valid iband magnitudes\n",
    "invmask = np.isnan(objtab['r_psfMag'])\n",
    "mask = ~invmask\n",
    "ncand = len(np.where(mask)[0])\n",
    "print('Found ' + str(ncand) + ' candidate targets')\n",
    "objtab[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421590e-e256-44b1-9c3c-3b67ca4b2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATOUSHA'S IMPLEMENTATION OF THE KMTNet DETECTION ALGORITHM\n",
    "def run_kmtnet_fit(times, fluxes, flux_errors):\n",
    "\n",
    "    \"\"\"\n",
    "    Fit a two-parameter PSPL (KMTNet-Algorithm) model to a light curve,\n",
    "    using a grid search over t0 and t_eff,\n",
    "    and return Delta_Chi2 along with best-fit parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure inputs are numpy arrays\n",
    "    times = np.asarray(times)\n",
    "    fluxes = np.asarray(fluxes)\n",
    "    flux_errors = np.asarray(flux_errors)\n",
    "\n",
    "    # Filter out NaNs from input data before creating DataFrame\n",
    "    valid_data_indices = ~np.isnan(times) & ~np.isnan(fluxes) & ~np.isnan(flux_errors) & (flux_errors > 0)\n",
    "    times, fluxes, flux_errors = times[valid_data_indices], fluxes[valid_data_indices], flux_errors[valid_data_indices]\n",
    "\n",
    "    if len(times) < 5: # KMTNet fit needs sufficient data points\n",
    "        return None, None, None # Not enough data for KMTNet fit\n",
    "\n",
    "    data_df = pd.DataFrame({\n",
    "        'time': times,\n",
    "        'flux': fluxes,\n",
    "        'flux_err': flux_errors\n",
    "    })\n",
    "\n",
    "    # --- Model Definitions ---\n",
    "    # Functions for high and low magnification regimes,\n",
    "    # params: (t, f_1, f_0, t0, t_eff)\n",
    "    \n",
    "    def Ft_high(t, f_1, f_0, t0, t_eff):\n",
    "        # High-mag analytic approximation \n",
    "        Q = 1 + ((t - t0) / t_eff)**2\n",
    "        return np.abs(f_1) * (Q**(-1.0 / 2)) + np.abs(f_0)\n",
    "\n",
    "    def Ft_low(t, f_1, f_0, t0, t_eff):\n",
    "         # Low-mag analytic approximation\n",
    "        Q = 1 + ((t - t0) / t_eff)**2\n",
    "        return np.abs(f_1) * (1 - (1 + Q / 2)**-2)**(-1.0 / 2) + np.abs(f_0)\n",
    "\n",
    "     # --- Chi2 Functions for Minimization ---\n",
    "    def chi2_high(f_params, t, flux, flux_err, t0, teff):\n",
    "        # Compute chi^2 for the high-mag model (minimize over f1, f0)\n",
    "        f_1, f_0 = f_params\n",
    "        model = Ft_high(t, f_1, f_0, t0, teff)\n",
    "        inv_sigma2 = 1.0 / (flux_err**2)\n",
    "        return np.sum((flux - model)**2 * inv_sigma2)\n",
    "\n",
    "    def chi2_low(f_params, t, flux, flux_err, t0, teff):\n",
    "        # Compute chi^2 for the low-mag model\n",
    "        f_1, f_0 = f_params\n",
    "        model = Ft_low(t, f_1, f_0, t0, teff)\n",
    "        inv_sigma2 = 1.0 / (flux_err**2)\n",
    "        return np.sum((flux - model)**2 * inv_sigma2)\n",
    "\n",
    "    # --- Grid Search: Build t0-teff grid for nonlinear fitting ---\n",
    "    teff_min, teff_max = 1, 100\n",
    "    teff_list, t0_tE_list = [], []\n",
    "    current_teff = teff_min\n",
    "\n",
    "    # Build teff grid (teff_{k+1} = (1 + delta) * teff_k)\n",
    "    while current_teff <= teff_max:\n",
    "        teff_list.append(current_teff)\n",
    "        delta = 1/5 if current_teff < 1 else 1/3\n",
    "        current_teff *= (1 + delta)\n",
    "\n",
    "    # For each teff, build the grid of t0 values\n",
    "    t0_min, t0_max = np.min(times), np.max(times)\n",
    "    for teff in teff_list:\n",
    "        t0_current = t0_min\n",
    "        while t0_current <= t0_max:\n",
    "            t0_tE_list.append([t0_current, teff])\n",
    "            delta = 1/5 if teff < 1 else 1/3\n",
    "            t0_current += delta * teff\n",
    "\n",
    "    # If no grid was produced, exit\n",
    "    if not t0_tE_list: return None, None, None\n",
    "\n",
    "\n",
    "    # --- Main Grid Fit Loop ---\n",
    "    param1, param2 = [], []  # Will store fit results for high and low mag regimes\n",
    "    f_initial = [0.01, 0.99] # Initial guess for f_1, f_0\n",
    "\n",
    "    for i, (t0_val, teff_val) in enumerate(t0_tE_list):\n",
    "        # For each grid point, select data within the relevant window (t0 Â± 7 teff)\n",
    "        df_i = data_df[(data_df['time'] > (t0_val - 7 * teff_val)) & (data_df['time'] < (t0_val + 7 * teff_val))]\n",
    "\n",
    "        if len(df_i) < 10:\n",
    "            continue # Skip if not enough data in interval\n",
    "\n",
    "        # Prepare arguments for minimize (t, flux, flux_err, t0_val, teff_val)\n",
    "        args = (df_i['time'].values, df_i['flux'].values, df_i['flux_err'].values, t0_val, teff_val)\n",
    "\n",
    "        try:\n",
    "            # Fit the high-magnification model for current grid point\n",
    "            result1 = minimize(chi2_high, f_initial, args=args, method='BFGS')\n",
    "            # Compute chi2 for the entire dataset using best-fit parameters\n",
    "            model_diff1 = data_df['flux'].values - Ft_high(data_df['time'].values, result1.x[0], result1.x[1], t0_val, teff_val)\n",
    "            chi2_all1 = np.sum((model_diff1)**2 * (1.0 / (data_df['flux_err'].values**2)))\n",
    "\n",
    "\n",
    "            # Fit the low-magnification model\n",
    "            result2 = minimize(chi2_low, f_initial, args=args, method='BFGS')\n",
    "            model_diff2 = data_df['flux'].values - Ft_low(data_df['time'].values, result2.x[0], result2.x[1], t0_val, teff_val)\n",
    "            chi2_all2 = np.sum((model_diff2)**2 * (1.0 / (data_df['flux_err'].values**2)))\n",
    "\n",
    "            # Store: [index, t0, teff, f1, f0, local_chi2, window_npts, global_chi2, npts]\n",
    "            param1.append([i, t0_val, teff_val, result1.x[0], result1.x[1], result1.fun,\n",
    "                            len(df_i), chi2_all1, len(data_df)])\n",
    "            param2.append([i, t0_val, teff_val, result2.x[0], result2.x[1], result2.fun,\n",
    "                            len(df_i), chi2_all2, len(data_df)])\n",
    "        except Exception as e:\n",
    "            # If optimization fails, print a warning but continue\n",
    "            print(f\"Warning: KMTNet minimize failed for iteration {i}: {e}\")\n",
    "            continue \n",
    "\n",
    "    # If no fits were successful, exit\n",
    "    if not param1 and not param2: return None, None, None \n",
    "\n",
    "    # --- Select Best-fit Parameters ---\n",
    "    # Find best fits: lowest chi2 on entire dataset for both regimes\n",
    "    min_value1 = min(param1, key=lambda x: x[7])\n",
    "    min_value2 = min(param2, key=lambda x: x[7])\n",
    "\n",
    "    # Use the regime (high or low mag) with the best global chi2\n",
    "    if min_value1 < min_value2:\n",
    "              min_value = min_value1\n",
    "              param = param1\n",
    "              F_t = Ft_high\n",
    "              which_regim = 'high'\n",
    "\n",
    "    else:\n",
    "              min_value = min_value2\n",
    "              param = param2\n",
    "              F_t = Ft_low\n",
    "              which_regim = 'low'\n",
    "\n",
    "    # Extract the precise parameters where chi2 is minimized\n",
    "    for sublist in param:\n",
    "        if sublist[7] == min_value[7]:\n",
    "            parameter = sublist\n",
    "\n",
    "\n",
    "\n",
    "    chi_mlens = parameter[7] # Minimum chi2 for microlensing fit\n",
    "    t0 = parameter[1]\n",
    "    t_eff = parameter[2]\n",
    "    f1 = parameter[3]\n",
    "    f0 = parameter[4]\n",
    "\n",
    "    # --- Linear Fit for Flat Model ---\n",
    "    # Fit a constant flux to the light curve in the same window\n",
    "    data_df_interval = data_df[(data_df['time'] > (t0 - 7 * t_eff)) & (data_df['time'] < (t0 + 7 * t_eff))]\n",
    "\n",
    "    if len(data_df_interval) == 0:\n",
    "        # Fallback to global mean if window is empty\n",
    "        mean_flux_interval = np.mean(data_df['flux'].values)\n",
    "    else:\n",
    "        # Ensure weights are valid (not zero or inf)\n",
    "        weights = 1.0 / (data_df_interval['flux_err'].values**2)\n",
    "        valid_weights_indices = ~np.isinf(weights) & ~np.isnan(weights) & (weights > 0)\n",
    "        if np.sum(valid_weights_indices) > 0:\n",
    "            mean_flux_interval = ws.weighted_mean(data_df_interval['flux'].values[valid_weights_indices],\n",
    "                                                  weights[valid_weights_indices])\n",
    "        else:\n",
    "            mean_flux_interval = np.mean(data_df['flux'].values)\n",
    "\n",
    "    # Compute chi2 for flat line fit\n",
    "    chi2_linearfit = np.sum((data_df['flux'] - mean_flux_interval)**2 / (data_df['flux_err']) ** 2)\n",
    "\n",
    "\n",
    "     # --- Compute Metric and Return ---\n",
    "    if chi2_linearfit == 0:\n",
    "        delta_chi_squared_kmt = 0\n",
    "    else:\n",
    "        delta_chi_squared_kmt = (abs(chi_mlens - chi2_linearfit) / chi2_linearfit)\n",
    "\n",
    "    # Return: delta chi2, best-fit physical params\n",
    "    # If delta_chi_squared_kmt > 0.9, the light curve would be a microlensing candidate.\n",
    "    return delta_chi_squared_kmt, (t0, t_eff, f1, f0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9016bf-df48-4833-aaac-816f678aaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_radius = 0.5/3600.0\n",
    "\n",
    "with open('./mulens_candidates.dat', 'w') as fout:\n",
    "\n",
    "    fout.write('# diaObjectId   coord_ra  coord_dec  delta_chi_squared_kmt  t0  t_eff  f1  f0\\n')\n",
    "    \n",
    "\n",
    "    for target in objtab[mask]:\n",
    "        query = \"SELECT fsodo.diaObjectId, fsodo.coord_ra, fsodo.coord_dec, \" \\\n",
    "                    \"fsodo.visit, fsodo.detector, fsodo.band, \" \\\n",
    "                    \"fsodo.psfDiffFlux, fsodo.psfDiffFluxErr, \" \\\n",
    "                    \"fsodo.psfFlux as psfFlux, fsodo.psfFluxErr, \" \\\n",
    "                    \"vis.expMidptMJD \" \\\n",
    "                    \"FROM dp1.ForcedSourceOnDiaObject as fsodo \" \\\n",
    "                    \"JOIN dp1.Visit as vis ON vis.visit = fsodo.visit \" \\\n",
    "                    \"WHERE CONTAINS (POINT('ICRS', coord_ra, coord_dec), \" \\\n",
    "                    \"CIRCLE('ICRS', \" + str(target['coord_ra']) + \", \" \\\n",
    "                    + str(target['coord_dec']) + \", \" + str(target_radius) + \")) = 1 \"\n",
    "        job = service.submit_job(query)\n",
    "        job.run()\n",
    "        job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "        print('Searching at coords: ' + str(target['coord_ra']) + '  ' + str(target['coord_dec']) + ' ' + repr(job.phase))\n",
    "        if job.phase == 'ERROR':\n",
    "            job.raise_if_error()\n",
    "        assert job.phase == 'COMPLETED'\n",
    "        forced_sources = job.fetch_result().to_table()\n",
    "        print(' -> Found ' + str(np.sum((forced_sources['band'] == 'r'))) + ' observations')\n",
    "        #print(forced_sources)\n",
    "        \n",
    "        # If DiaObjects are found, assume for the moment that the top target is the closest match\n",
    "        # and run the KMTNet algorithm over all of r-band lightcurve data, since this seems to have the \n",
    "        # most visits\n",
    "        if len(forced_sources) > 0:\n",
    "            rband = np.where(forced_sources['band'] == 'r')\n",
    "            \n",
    "            times = forced_sources[rband]['expMidptMJD']\n",
    "            fluxes = forced_sources[rband]['psfFlux']\n",
    "            flux_err = forced_sources[rband]['psfFluxErr']\n",
    "            \n",
    "            delta_chi_squared_kmt, (t0, t_eff, f1, f0) = run_kmtnet_fit(times, fluxes, flux_err)\n",
    "\n",
    "            print(' => ' + str(target['objectId']) + ' delta chisq=' + str(delta_chi_squared_kmt))\n",
    "            \n",
    "            if delta_chi_squared_kmt >= 0.9:\n",
    "                fout.write(str(target['objectId'])\n",
    "                           + '  ' + str(target['coord_ra'])\n",
    "                           + '  ' + str(target['coord_dec']) \n",
    "                           + '  ' + str(delta_chi_squared_kmt)\n",
    "                           + '  ' + str(t0) \n",
    "                           + '  ' + str(t_eff) \n",
    "                           + '  ' + str(f1) \n",
    "                           + '  ' + str(f0)\n",
    "                           + '\\n')\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0bf46b-7832-4f02-aaa0-f36329bd3da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
